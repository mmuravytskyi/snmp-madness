{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import jax\n",
    "import optax\n",
    "import data\n",
    "import dataclasses\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import functools as ft\n",
    "import haiku as hk\n",
    "import typing as t\n",
    "import jax.numpy as jnp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = int(24*5*60/5)\n",
    "BATCH_SIZE = 2\n",
    "SPLIT = 0.85\n",
    "LEARNING_RATE = 1e-4\n",
    "SEED = 2137\n",
    "NUM_TRAINING_STEPS = 15000\n",
    "EVAL_INTERVAL = 100\n",
    "EMBEDDING_SIZE = 4\n",
    "\n",
    "VOCAB_SIZE = 256\n",
    "PAD_TOKEN = 0\n",
    "GRAD_CLIP_VALUE = 1\n",
    "\n",
    "NUM_LAYERS = 3\n",
    "NUM_HEADS = 6  # Number of attention heads.\n",
    "MODEL_SIZE = 128\n",
    "KEY_SIZE = 32\n",
    "DROPOUT_RATE = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingState(t.NamedTuple):\n",
    "  \"\"\"Container for the training state.\"\"\"\n",
    "  params: hk.Params\n",
    "  opt_state: optax.OptState\n",
    "  rng: jax.Array\n",
    "  step: jax.Array\n",
    "\n",
    "class Batch(t.NamedTuple):\n",
    "    inputs: np.ndarray  # Integer tokens, shape [B, T]\n",
    "    targets: np.ndarray  # Integer tokens, shape [B, T]\n",
    "\n",
    "Metrics = t.MutableMapping[str, t.Any]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def local_label_smoothing(arr: jnp.array, std: int = 2, mean: float = 0.7):\n",
    "    # assert arr.shape[1] % EMBEDDING_SIZE == 0\n",
    "    # [0, 0, 0, 1, 0, 0]\n",
    "    #   into\n",
    "    # [0, 0.05, 0.1, 0.7, 0.1, 0.05]\n",
    "    il = jnp.argmax(arr) + 2*std\n",
    "    arr = arr * mean\n",
    "    _lin = jnp.arange(std) + 1\n",
    "    coef  = (1 - mean) / 2 / _lin.sum()\n",
    "    c = jnp.apply_along_axis(lambda x: jnp.convolve(jnp.array([.05, .1, .7, .1, .05]), x, mode=\"same\"), -1, arr)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def to_bytes(arr):\n",
    "  \"\"\" Converts an array of uint32 into an array of bytes in little endian\"\"\"\n",
    "\n",
    "  @ft.partial(jax.vmap, in_axes=(None, 0), out_axes=-1)\n",
    "  def _to_bytes(arr, byte_index:int):\n",
    "    mask = 0xFF << (8 * byte_index)\n",
    "    b = (arr & mask) >> 8 * byte_index\n",
    "    return  b.astype(jnp.uint8)\n",
    "\n",
    "  return _to_bytes(arr, jnp.arange(4))\n",
    "\n",
    "@ft.partial(jax.jit, static_argnames=(\"axis\"))\n",
    "def from_bytes(array, axis):\n",
    "  \"\"\" Converts an array of bytes in little endian  into an array of uint32\"\"\"\n",
    "\n",
    "  @ft.partial(jax.vmap, in_axes=(axis, -1))\n",
    "  def _from_bytes(arr, byte_index):\n",
    "    return arr << 8 * byte_index\n",
    "\n",
    "  return jnp.sum(_from_bytes(array, jnp.arange(4)), axis=axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdl = data.SimpleDataLoader(\"../data/samples_5m_subset_v1.csv\",\n",
    "                            BLOCK_SIZE,\n",
    "                            BATCH_SIZE,\n",
    "                            EMBEDDING_SIZE,\n",
    "                            SPLIT,\n",
    "                            normalize=False,\n",
    "                            log=False,\n",
    "                            shift=False,\n",
    "                            batch_first=True\n",
    "                            )\n",
    "train_di = sdl.get_data_iter(\"train\")\n",
    "test_di = sdl.get_data_iter(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1440)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expl_batch = next(train_di)\n",
    "expl_batch[\"target\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([877202, 764640, 846270, 898147], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expl_batch['input'][0, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([146,  98,  13,   0, 224, 170,  11,   0, 190, 233,  12,   0,  99,\n",
       "       180,  13,   0], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_bytes(expl_batch['input']).reshape(BATCH_SIZE, BLOCK_SIZE*4)[0, :16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[146,  98,  13,   0],\n",
       "       [224, 170,  11,   0],\n",
       "       [190, 233,  12,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_bytes(expl_batch['input'])[0, :3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_data(batch: dict):\n",
    "    _inputs = to_bytes(batch['input'])\n",
    "    _targets = to_bytes(batch['target'])\n",
    "    # TODO: make it a bit cleaner\n",
    "    _inputs = _inputs.reshape((BATCH_SIZE, EMBEDDING_SIZE*BLOCK_SIZE))\n",
    "    _targets = _targets.reshape((BATCH_SIZE, EMBEDDING_SIZE*BLOCK_SIZE))\n",
    "    return Batch(inputs=_inputs, targets=_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def apply_byte_error_weights(arr: jnp.array):\n",
    "    assert arr.shape[1] % EMBEDDING_SIZE == 0\n",
    "    c = arr.shape[1] // EMBEDDING_SIZE\n",
    "    weights = jnp.array([1., 2., 3., 4.] * c)\n",
    "    return weights*arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5760)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_inputs = preproc_data(expl_batch)\n",
    "_inputs.inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from: https://github.com/deepmind/dm-haiku/tree/main/examples/transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Didactic exasmple of an autoregressive Transformer-based language model.\n",
    "Glossary of shapes:\n",
    "- B: Batch size.\n",
    "- T: Sequence length.\n",
    "- D: Model embedding size.\n",
    "- H: Number of attention heads.\n",
    "- V: Vocabulary size.\n",
    "\"\"\"\n",
    "\n",
    "def layer_norm(x: jax.Array) -> jax.Array:\n",
    "  \"\"\"Applies a unique LayerNorm to x with default settings.\"\"\"\n",
    "  ln = hk.LayerNorm(axis=-1, create_scale=True, create_offset=True)\n",
    "  return ln(x)\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Transformer(hk.Module):\n",
    "  \"\"\"A transformer stack.\"\"\"\n",
    "\n",
    "  num_heads: int\n",
    "  num_layers: int\n",
    "  key_size: int\n",
    "  dropout_rate: float\n",
    "  widening_factor: int = 4\n",
    "  name: t.Optional[str] = None\n",
    "\n",
    "  def __call__(\n",
    "      self,\n",
    "      embeddings: jax.Array,  # [B, T, D]\n",
    "      mask: jax.Array,  # [B, T]\n",
    "      *,\n",
    "      is_training: bool = True,\n",
    "  ) -> jax.Array:  # [B, T, D]\n",
    "    \"\"\"Transforms input embedding sequences to output embedding sequences.\"\"\"\n",
    "\n",
    "    initializer = hk.initializers.VarianceScaling(2 / self.num_layers)\n",
    "    dropout_rate = self.dropout_rate if is_training else 0.\n",
    "    _, seq_len, model_size = embeddings.shape\n",
    "\n",
    "    # Compute causal mask for autoregressive sequence modelling.\n",
    "    mask = mask[:, None, None, :]  # [B, H=1, T'=1, T]\n",
    "    causal_mask = np.tril(np.ones((1, 1, seq_len, seq_len)))  # [B=1, H=1, T, T]\n",
    "    mask = mask * causal_mask  # [B, H=1, T, T]\n",
    "\n",
    "    h = embeddings\n",
    "    for _ in range(self.num_layers):\n",
    "      # First the attention block.\n",
    "      attn_block = hk.MultiHeadAttention(\n",
    "          num_heads=self.num_heads,\n",
    "          key_size=self.key_size,\n",
    "          model_size=model_size,\n",
    "          w_init=initializer,\n",
    "      )\n",
    "      h_norm = layer_norm(h)\n",
    "#       h_attn = attn_block(h_norm, h_norm, h_norm, mask=mask)\n",
    "      h_attn = attn_block(h_norm, h_norm, h_norm)\n",
    "      h_attn = hk.dropout(hk.next_rng_key(), dropout_rate, h_attn)\n",
    "      h = h + h_attn\n",
    "\n",
    "      # Then the dense block.\n",
    "      dense_block = hk.Sequential([\n",
    "          hk.Linear(self.widening_factor * model_size, w_init=initializer),\n",
    "          jax.nn.gelu,\n",
    "          hk.Linear(model_size, w_init=initializer),\n",
    "      ])\n",
    "      h_norm = layer_norm(h)\n",
    "      h_dense = dense_block(h_norm)\n",
    "      h_dense = hk.dropout(hk.next_rng_key(), dropout_rate, h_dense)\n",
    "      h = h + h_dense\n",
    "\n",
    "    return layer_norm(h)\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class TransformerModel(hk.Module):\n",
    "  \"\"\"An autoregressive transformer-based model.\"\"\"\n",
    "\n",
    "  transformer: Transformer\n",
    "  model_size: int\n",
    "  vocab_size: int\n",
    "  pad_token: int\n",
    "  name: t.Optional[str] = None\n",
    "\n",
    "  def __call__(\n",
    "      self,\n",
    "      tokens: jax.Array,\n",
    "      *,\n",
    "      is_training: bool = True,\n",
    "  ) -> jax.Array:\n",
    "    \"\"\"Forward pass, producing a sequence of logits.\"\"\"\n",
    "    input_mask = jnp.greater(tokens, self.pad_token)\n",
    "    unused_batch_size, seq_len = tokens.shape\n",
    "\n",
    "    # Embed the input tokens and positions.\n",
    "    embed_init = hk.initializers.TruncatedNormal(stddev=0.02)\n",
    "    token_embedding_map = hk.Embed(\n",
    "        self.vocab_size, embed_dim=self.model_size, w_init=embed_init)\n",
    "    token_embeddings = token_embedding_map(tokens)\n",
    "    positional_embeddings = hk.get_parameter(\n",
    "        'positional_embeddings', [seq_len, self.model_size], init=embed_init)\n",
    "    input_embeddings = token_embeddings + positional_embeddings  # [B, T, D]\n",
    "\n",
    "    # Run the transformer over the inputs.\n",
    "    embeddings = self.transformer(\n",
    "        input_embeddings,\n",
    "        input_mask,\n",
    "        is_training=is_training,\n",
    "    )  # [B, T, D]\n",
    "\n",
    "    # Decode the embeddings (here, we use untied weights).\n",
    "    return hk.Linear(self.vocab_size)(embeddings)  # [B, T, V]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(tokens: t.Union[np.ndarray, jax.Array]) -> jax.Array:\n",
    "    net = TransformerModel(\n",
    "        model_size=MODEL_SIZE,\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        pad_token=PAD_TOKEN,\n",
    "        transformer=Transformer(\n",
    "            num_heads=NUM_HEADS,\n",
    "            num_layers=NUM_LAYERS,\n",
    "            key_size=KEY_SIZE,\n",
    "            dropout_rate=DROPOUT_RATE,\n",
    "        ),\n",
    "    )\n",
    "    return net(tokens)\n",
    "\n",
    "# Create the optimiser.\n",
    "def make_optimizer() -> optax.GradientTransformation:\n",
    "    optimiser = optax.chain(\n",
    "      optax.clip_by_global_norm(GRAD_CLIP_VALUE),\n",
    "      optax.adam(LEARNING_RATE, b1=0.9, b2=0.99),\n",
    "    )\n",
    "    return optimiser\n",
    "\n",
    "# Create the loss.\n",
    "@hk.transform\n",
    "def loss_fn(batch: Batch) -> jax.Array:\n",
    "    \"\"\"Computes the (scalar) loss on `data` w.r.t. params.\"\"\"\n",
    "    inp = batch.inputs[:, 3:]\n",
    "    logits = forward(inp)\n",
    "    \n",
    "    targets = jax.nn.one_hot(batch.targets[:,  :-3], VOCAB_SIZE)  # (B, T*D, 256)\n",
    "    # targets = local_label_smoothing(targets)\n",
    "    assert logits.shape == targets.shape\n",
    "    log_likelihood = jnp.sum(targets * jax.nn.log_softmax(logits, axis=-1), axis=-1)\n",
    "#    log_likelihood = apply_byte_error_weights(log_likelihood)\n",
    "    return -log_likelihood.mean()  # NLL per token.\n",
    "\n",
    "@jax.jit\n",
    "def update(state: TrainingState, batch) -> t.Tuple[TrainingState, Metrics]:\n",
    "    \"\"\"Does an SGD step and returns metrics.\"\"\"\n",
    "    rng, new_rng = jax.random.split(state.rng)\n",
    "    loss_and_grad_fn = jax.value_and_grad(loss_fn.apply)\n",
    "    loss, gradients = loss_and_grad_fn(state.params, rng, batch)\n",
    "\n",
    "    optimiser = make_optimizer()\n",
    "    updates, new_opt_state = optimiser.update(gradients, state.opt_state)\n",
    "    new_params = optax.apply_updates(state.params, updates)\n",
    "\n",
    "    new_state = TrainingState(\n",
    "        params=new_params,\n",
    "        opt_state=new_opt_state,\n",
    "        rng=new_rng,\n",
    "        step=state.step + 1,\n",
    "    )\n",
    "\n",
    "    metrics = {\n",
    "        'step': state.step,\n",
    "        'loss': loss,\n",
    "    }\n",
    "    return new_state, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(SEED)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "init_batch = preproc_data(expl_batch)\n",
    "initial_params = loss_fn.init(init_rng, init_batch)\n",
    "\n",
    "initial_opt_state = make_optimizer().init(initial_params)\n",
    "initial_state =  TrainingState(\n",
    "    params=initial_params,\n",
    "    opt_state=initial_opt_state,\n",
    "    rng=rng,\n",
    "    step=jnp.array(0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.759206771850586, 'step': 0.0, 'steps_per_sec': 7.673625467242626, 'valid_loss': 5.146252155303955}\n",
      "{'loss': 4.566343307495117, 'step': 100.0, 'steps_per_sec': 7.936330793475272, 'valid_loss': 4.398922920227051}\n",
      "{'loss': 4.49170446395874, 'step': 200.0, 'steps_per_sec': 8.01583404259914, 'valid_loss': 3.288595676422119}\n",
      "{'loss': 4.178997993469238, 'step': 300.0, 'steps_per_sec': 8.127671543400588, 'valid_loss': 3.3260915279388428}\n",
      "{'loss': 3.1556215286254883, 'step': 400.0, 'steps_per_sec': 8.281527844964607, 'valid_loss': 3.2085752487182617}\n",
      "{'loss': 3.7026379108428955, 'step': 500.0, 'steps_per_sec': 8.210676402249193, 'valid_loss': 3.6137075424194336}\n",
      "{'loss': 3.8262696266174316, 'step': 600.0, 'steps_per_sec': 8.03250596538869, 'valid_loss': 4.120869159698486}\n",
      "{'loss': 1.9641859531402588, 'step': 700.0, 'steps_per_sec': 7.990386931493933, 'valid_loss': 3.7649528980255127}\n",
      "{'loss': 2.8108365535736084, 'step': 800.0, 'steps_per_sec': 8.007288739162211, 'valid_loss': 3.400843620300293}\n",
      "{'loss': 3.6299920082092285, 'step': 900.0, 'steps_per_sec': 8.130417171437097, 'valid_loss': 4.265477657318115}\n",
      "{'loss': 3.1441967487335205, 'step': 1000.0, 'steps_per_sec': 8.326612374100879, 'valid_loss': 4.459436893463135}\n",
      "{'loss': 2.8979735374450684, 'step': 1100.0, 'steps_per_sec': 8.272125879298354, 'valid_loss': 3.7417116165161133}\n",
      "{'loss': 2.471073627471924, 'step': 1200.0, 'steps_per_sec': 8.171066907557352, 'valid_loss': 3.746562957763672}\n",
      "{'loss': 4.306421756744385, 'step': 1300.0, 'steps_per_sec': 8.05953648072892, 'valid_loss': 3.2749948501586914}\n",
      "{'loss': 2.717759132385254, 'step': 1400.0, 'steps_per_sec': 8.045407181365457, 'valid_loss': 3.862637519836426}\n",
      "{'loss': 2.1587369441986084, 'step': 1500.0, 'steps_per_sec': 8.031855007834704, 'valid_loss': 2.8508832454681396}\n",
      "{'loss': 4.168216705322266, 'step': 1600.0, 'steps_per_sec': 8.19350923800046, 'valid_loss': 2.8072261810302734}\n",
      "{'loss': 2.628340005874634, 'step': 1700.0, 'steps_per_sec': 8.291228352127103, 'valid_loss': 3.313019037246704}\n",
      "{'loss': 2.3047807216644287, 'step': 1800.0, 'steps_per_sec': 8.203443964554069, 'valid_loss': 3.4844863414764404}\n",
      "{'loss': 2.056943655014038, 'step': 1900.0, 'steps_per_sec': 7.980668925282169, 'valid_loss': 1.0413143634796143}\n",
      "{'loss': 3.2431163787841797, 'step': 2000.0, 'steps_per_sec': 8.000690519802134, 'valid_loss': 2.877338171005249}\n",
      "{'loss': 4.068580150604248, 'step': 2100.0, 'steps_per_sec': 8.004636932912627, 'valid_loss': 3.735064744949341}\n",
      "{'loss': 4.206955909729004, 'step': 2200.0, 'steps_per_sec': 8.094956335372778, 'valid_loss': 4.271401882171631}\n",
      "{'loss': 2.550206184387207, 'step': 2300.0, 'steps_per_sec': 8.325219115636019, 'valid_loss': 3.101104259490967}\n",
      "{'loss': 3.6393325328826904, 'step': 2400.0, 'steps_per_sec': 8.276387795766183, 'valid_loss': 4.27606201171875}\n",
      "{'loss': 3.6934821605682373, 'step': 2500.0, 'steps_per_sec': 8.2066342561371, 'valid_loss': 3.116870641708374}\n",
      "{'loss': 2.0284006595611572, 'step': 2600.0, 'steps_per_sec': 8.019400724978524, 'valid_loss': 2.5741453170776367}\n",
      "{'loss': 3.2783613204956055, 'step': 2700.0, 'steps_per_sec': 7.977016598257074, 'valid_loss': 2.754744052886963}\n",
      "{'loss': 3.428903102874756, 'step': 2800.0, 'steps_per_sec': 8.042043686836832, 'valid_loss': 4.173402309417725}\n",
      "{'loss': 2.3382411003112793, 'step': 2900.0, 'steps_per_sec': 8.26661589590101, 'valid_loss': 2.1903319358825684}\n",
      "{'loss': 3.8337032794952393, 'step': 3000.0, 'steps_per_sec': 8.277280562975317, 'valid_loss': 3.552785634994507}\n",
      "{'loss': 3.25923752784729, 'step': 3100.0, 'steps_per_sec': 8.195526797694015, 'valid_loss': 2.938406467437744}\n",
      "{'loss': 2.619901180267334, 'step': 3200.0, 'steps_per_sec': 7.9632142116629545, 'valid_loss': 3.378499984741211}\n",
      "{'loss': 2.2983052730560303, 'step': 3300.0, 'steps_per_sec': 8.003899452280228, 'valid_loss': 3.4330945014953613}\n",
      "{'loss': 2.603411912918091, 'step': 3400.0, 'steps_per_sec': 7.98204797388381, 'valid_loss': 3.2310702800750732}\n",
      "{'loss': 2.5077452659606934, 'step': 3500.0, 'steps_per_sec': 8.286219330838493, 'valid_loss': 2.170111656188965}\n",
      "{'loss': 3.0400125980377197, 'step': 3600.0, 'steps_per_sec': 8.325436750550379, 'valid_loss': 3.2050836086273193}\n",
      "{'loss': 3.3340349197387695, 'step': 3700.0, 'steps_per_sec': 8.223570641047532, 'valid_loss': 3.2347373962402344}\n",
      "{'loss': 2.920610189437866, 'step': 3800.0, 'steps_per_sec': 8.175748623736649, 'valid_loss': 1.4509235620498657}\n",
      "{'loss': 3.299625873565674, 'step': 3900.0, 'steps_per_sec': 8.029957189109878, 'valid_loss': 4.304331302642822}\n",
      "{'loss': 3.22751522064209, 'step': 4000.0, 'steps_per_sec': 8.059232642191818, 'valid_loss': 2.099308490753174}\n",
      "{'loss': 3.9336657524108887, 'step': 4100.0, 'steps_per_sec': 8.046484822511612, 'valid_loss': 2.5250065326690674}\n",
      "{'loss': 3.2137351036071777, 'step': 4200.0, 'steps_per_sec': 8.288368635489759, 'valid_loss': 4.193914890289307}\n",
      "{'loss': 3.7729835510253906, 'step': 4300.0, 'steps_per_sec': 8.256251536247326, 'valid_loss': 4.376927852630615}\n",
      "{'loss': 2.8953843116760254, 'step': 4400.0, 'steps_per_sec': 8.212058112331128, 'valid_loss': 4.037929534912109}\n",
      "{'loss': 3.766800880432129, 'step': 4500.0, 'steps_per_sec': 8.062523742257683, 'valid_loss': 2.8635659217834473}\n",
      "{'loss': 2.862245798110962, 'step': 4600.0, 'steps_per_sec': 8.027389289100073, 'valid_loss': 3.6884512901306152}\n",
      "{'loss': 4.111240863800049, 'step': 4700.0, 'steps_per_sec': 8.03422523434667, 'valid_loss': 4.110337257385254}\n",
      "{'loss': 3.2325797080993652, 'step': 4800.0, 'steps_per_sec': 8.286946393467783, 'valid_loss': 2.478691339492798}\n",
      "{'loss': 3.649791955947876, 'step': 4900.0, 'steps_per_sec': 8.310420406852577, 'valid_loss': 2.5741753578186035}\n",
      "{'loss': 4.008030414581299, 'step': 5000.0, 'steps_per_sec': 8.200080442550156, 'valid_loss': 3.5226128101348877}\n",
      "{'loss': 2.727832078933716, 'step': 5100.0, 'steps_per_sec': 8.168861540139478, 'valid_loss': 4.266569137573242}\n",
      "{'loss': 2.604179620742798, 'step': 5200.0, 'steps_per_sec': 8.013932455623582, 'valid_loss': 3.4107046127319336}\n",
      "{'loss': 4.211334705352783, 'step': 5300.0, 'steps_per_sec': 7.999991149912134, 'valid_loss': 3.4495251178741455}\n",
      "{'loss': 2.4441168308258057, 'step': 5400.0, 'steps_per_sec': 8.053491275287167, 'valid_loss': 2.8004186153411865}\n",
      "{'loss': 2.5049517154693604, 'step': 5500.0, 'steps_per_sec': 8.291822202846605, 'valid_loss': 3.6886589527130127}\n",
      "{'loss': 2.3376576900482178, 'step': 5600.0, 'steps_per_sec': 8.20881877944534, 'valid_loss': 2.0228970050811768}\n",
      "{'loss': 1.7689913511276245, 'step': 5700.0, 'steps_per_sec': 8.184372548427328, 'valid_loss': 3.135193109512329}\n",
      "{'loss': 1.225872278213501, 'step': 5800.0, 'steps_per_sec': 8.051414286592642, 'valid_loss': 3.826075315475464}\n",
      "{'loss': 3.058527946472168, 'step': 5900.0, 'steps_per_sec': 8.00299184112713, 'valid_loss': 3.322108507156372}\n",
      "{'loss': 3.080829381942749, 'step': 6000.0, 'steps_per_sec': 8.050715910904344, 'valid_loss': 3.0256922245025635}\n",
      "{'loss': 3.0896382331848145, 'step': 6100.0, 'steps_per_sec': 8.277627039883093, 'valid_loss': 3.196363687515259}\n",
      "{'loss': 3.7642123699188232, 'step': 6200.0, 'steps_per_sec': 8.306925174070845, 'valid_loss': 3.7642085552215576}\n",
      "{'loss': 2.1931700706481934, 'step': 6300.0, 'steps_per_sec': 8.220873892781075, 'valid_loss': 3.7801403999328613}\n",
      "{'loss': 2.9625728130340576, 'step': 6400.0, 'steps_per_sec': 8.17144816945942, 'valid_loss': 3.68266224861145}\n",
      "{'loss': 3.6370785236358643, 'step': 6500.0, 'steps_per_sec': 8.04933883235665, 'valid_loss': 2.529266119003296}\n",
      "{'loss': 3.229290246963501, 'step': 6600.0, 'steps_per_sec': 8.017043067018081, 'valid_loss': 2.2089803218841553}\n",
      "{'loss': 2.359145164489746, 'step': 6700.0, 'steps_per_sec': 8.10892078067742, 'valid_loss': 2.3220338821411133}\n",
      "{'loss': 2.443479299545288, 'step': 6800.0, 'steps_per_sec': 8.28925956624662, 'valid_loss': 1.9469090700149536}\n",
      "{'loss': 2.7322611808776855, 'step': 6900.0, 'steps_per_sec': 8.19485075169411, 'valid_loss': 2.077850103378296}\n",
      "{'loss': 2.228605270385742, 'step': 7000.0, 'steps_per_sec': 8.158264778435624, 'valid_loss': 1.8665380477905273}\n",
      "{'loss': 1.8017621040344238, 'step': 7100.0, 'steps_per_sec': 8.038704881031862, 'valid_loss': 1.3411906957626343}\n",
      "{'loss': 1.8315664529800415, 'step': 7200.0, 'steps_per_sec': 8.041662069983925, 'valid_loss': 2.0476579666137695}\n",
      "{'loss': 1.2528364658355713, 'step': 7300.0, 'steps_per_sec': 8.086313150607984, 'valid_loss': 1.31989324092865}\n",
      "{'loss': 1.1770325899124146, 'step': 7400.0, 'steps_per_sec': 8.315645693123962, 'valid_loss': 1.6119123697280884}\n",
      "{'loss': 1.5082736015319824, 'step': 7500.0, 'steps_per_sec': 8.301076140485986, 'valid_loss': 1.4318263530731201}\n",
      "{'loss': 1.434846043586731, 'step': 7600.0, 'steps_per_sec': 8.201046940082476, 'valid_loss': 1.0642940998077393}\n",
      "{'loss': 0.9400690793991089, 'step': 7700.0, 'steps_per_sec': 8.019690066989577, 'valid_loss': 1.400743842124939}\n",
      "{'loss': 1.0492033958435059, 'step': 7800.0, 'steps_per_sec': 8.041387636616514, 'valid_loss': 1.2072763442993164}\n",
      "{'loss': 1.16521418094635, 'step': 7900.0, 'steps_per_sec': 8.019057742972839, 'valid_loss': 0.6799800395965576}\n",
      "{'loss': 0.9831482768058777, 'step': 8000.0, 'steps_per_sec': 8.166594553763003, 'valid_loss': 0.8301566243171692}\n",
      "{'loss': 0.8288055062294006, 'step': 8100.0, 'steps_per_sec': 8.294344106326655, 'valid_loss': 0.760983943939209}\n",
      "{'loss': 0.8295219540596008, 'step': 8200.0, 'steps_per_sec': 8.219314129332998, 'valid_loss': 0.8434987664222717}\n",
      "{'loss': 0.7263687252998352, 'step': 8300.0, 'steps_per_sec': 8.102784074388444, 'valid_loss': 0.7003055214881897}\n",
      "{'loss': 0.8147823810577393, 'step': 8400.0, 'steps_per_sec': 8.010472676069421, 'valid_loss': 0.7397906184196472}\n",
      "{'loss': 0.3981567323207855, 'step': 8500.0, 'steps_per_sec': 8.03987843373434, 'valid_loss': 0.6096658706665039}\n",
      "{'loss': 0.5784246921539307, 'step': 8600.0, 'steps_per_sec': 8.118263807688747, 'valid_loss': 0.3385953903198242}\n",
      "{'loss': 0.3866216540336609, 'step': 8700.0, 'steps_per_sec': 8.307900073941687, 'valid_loss': 0.35029467940330505}\n",
      "{'loss': 0.33906105160713196, 'step': 8800.0, 'steps_per_sec': 8.219207181083288, 'valid_loss': 0.3380769193172455}\n",
      "{'loss': 0.32988864183425903, 'step': 8900.0, 'steps_per_sec': 8.157972332590857, 'valid_loss': 0.19325172901153564}\n",
      "{'loss': 0.3786230683326721, 'step': 9000.0, 'steps_per_sec': 7.974580386186221, 'valid_loss': 0.3016771078109741}\n",
      "{'loss': 0.17210178077220917, 'step': 9100.0, 'steps_per_sec': 7.947202718238973, 'valid_loss': 0.2761416733264923}\n",
      "{'loss': 0.18619978427886963, 'step': 9200.0, 'steps_per_sec': 8.085721715953415, 'valid_loss': 0.18753312528133392}\n",
      "{'loss': 0.2968284487724304, 'step': 9300.0, 'steps_per_sec': 8.333042439707784, 'valid_loss': 0.256610244512558}\n",
      "{'loss': 0.28955209255218506, 'step': 9400.0, 'steps_per_sec': 8.306562257142508, 'valid_loss': 0.19397297501564026}\n",
      "{'loss': 0.17310400307178497, 'step': 9500.0, 'steps_per_sec': 8.2296716434193, 'valid_loss': 0.1834147572517395}\n",
      "{'loss': 0.15348218381404877, 'step': 9600.0, 'steps_per_sec': 8.151768792012142, 'valid_loss': 0.18563105165958405}\n",
      "{'loss': 0.13875077664852142, 'step': 9700.0, 'steps_per_sec': 8.009716223566105, 'valid_loss': 0.17358408868312836}\n",
      "{'loss': 0.1994476020336151, 'step': 9800.0, 'steps_per_sec': 7.986798554178141, 'valid_loss': 0.15680581331253052}\n",
      "{'loss': 0.11016201227903366, 'step': 9900.0, 'steps_per_sec': 8.092730958271586, 'valid_loss': 0.06579522788524628}\n",
      "{'loss': 0.18241779506206512, 'step': 10000.0, 'steps_per_sec': 8.30292299707936, 'valid_loss': 0.07277815788984299}\n",
      "{'loss': 0.09904484450817108, 'step': 10100.0, 'steps_per_sec': 8.228930217333565, 'valid_loss': 0.0507943332195282}\n",
      "{'loss': 0.08359017968177795, 'step': 10200.0, 'steps_per_sec': 8.143046928274702, 'valid_loss': 0.14460664987564087}\n",
      "{'loss': 0.03471653163433075, 'step': 10300.0, 'steps_per_sec': 7.982689667301841, 'valid_loss': 0.08807115256786346}\n",
      "{'loss': 0.04149697348475456, 'step': 10400.0, 'steps_per_sec': 8.009908497343133, 'valid_loss': 0.0838441252708435}\n",
      "{'loss': 0.06648264080286026, 'step': 10500.0, 'steps_per_sec': 8.081778744181069, 'valid_loss': 0.030565356835722923}\n",
      "{'loss': 0.06591587513685226, 'step': 10600.0, 'steps_per_sec': 8.284941018517594, 'valid_loss': 0.07203669846057892}\n",
      "{'loss': 0.11115667223930359, 'step': 10700.0, 'steps_per_sec': 8.213493847131012, 'valid_loss': 0.057022709399461746}\n",
      "{'loss': 0.0344577431678772, 'step': 10800.0, 'steps_per_sec': 8.146813349697517, 'valid_loss': 0.01438208483159542}\n",
      "{'loss': 0.07251067459583282, 'step': 10900.0, 'steps_per_sec': 8.012477928121095, 'valid_loss': 0.03925326466560364}\n",
      "{'loss': 0.025495998561382294, 'step': 11000.0, 'steps_per_sec': 7.995780577445294, 'valid_loss': 0.08515468239784241}\n",
      "{'loss': 0.08944110572338104, 'step': 11100.0, 'steps_per_sec': 8.019574143677103, 'valid_loss': 0.05290660262107849}\n",
      "{'loss': 0.059184156358242035, 'step': 11200.0, 'steps_per_sec': 8.297839428107034, 'valid_loss': 0.02693752758204937}\n",
      "{'loss': 0.014850225299596786, 'step': 11300.0, 'steps_per_sec': 8.324031991100084, 'valid_loss': 0.02737804688513279}\n",
      "{'loss': 0.03021809086203575, 'step': 11400.0, 'steps_per_sec': 8.258870883881858, 'valid_loss': 0.01799572817981243}\n",
      "{'loss': 0.010119980201125145, 'step': 11500.0, 'steps_per_sec': 8.201869957298419, 'valid_loss': 0.014430612325668335}\n",
      "{'loss': 0.02870512567460537, 'step': 11600.0, 'steps_per_sec': 7.9873625241069846, 'valid_loss': 0.03470687195658684}\n",
      "{'loss': 0.027384135872125626, 'step': 11700.0, 'steps_per_sec': 8.027377612895236, 'valid_loss': 0.05409190058708191}\n",
      "{'loss': 0.06677591800689697, 'step': 11800.0, 'steps_per_sec': 8.071461860565346, 'valid_loss': 0.037323031574487686}\n",
      "{'loss': 0.006749982945621014, 'step': 11900.0, 'steps_per_sec': 8.280484578952182, 'valid_loss': 0.028913913294672966}\n",
      "{'loss': 0.020583905279636383, 'step': 12000.0, 'steps_per_sec': 8.205556958372377, 'valid_loss': 0.053132858127355576}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/net/ascratch/people/plgmuravytskyi/slurm_jobdir/2053545/tmp/ipykernel_1549980/2642790089.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mprev_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_rng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreproc_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_di\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'steps_per_sec'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msteps_per_sec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/haiku/_src/transform.py\u001b[0m in \u001b[0;36mapply_fn\u001b[0;34m(params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m           \"name (e.g. `f.apply(.., state=my_state)`)\")\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m       raise ValueError(\"If your transformed function uses `hk.{get,set}_state` \"\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/haiku/_src/transform.py\u001b[0m in \u001b[0;36mapply_fn\u001b[0;34m(params, state, rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnexpectedTracerError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnexpectedTracerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munexpected_tracer_hint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/ascratch/people/plgmuravytskyi/slurm_jobdir/2053545/tmp/ipykernel_1549980/1926883911.py\u001b[0m in \u001b[0;36mloss_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;34m\"\"\"Computes the (scalar) loss on `data` w.r.t. params.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#     outputs = jnp.zeros((BATCH_SIZE, 3, VOCAB_SIZE))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/ascratch/people/plgmuravytskyi/slurm_jobdir/2053545/tmp/ipykernel_1549980/1926883911.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m     11\u001b[0m         ),\n\u001b[1;32m     12\u001b[0m     )\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Create the optimiser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/haiku/_src/module.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0;31m# Module names are set in the constructor. If `f` is the constructor then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/software/testing/software/Python/3.9.6-GCCcore-11.2.0/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/haiku/_src/module.py\u001b[0m in \u001b[0;36mrun_interceptors\u001b[0;34m(bound_method, method_name, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \u001b[0;34m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minterceptor_stack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbound_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m   ctx = MethodContext(module=self,\n",
      "\u001b[0;32m/net/ascratch/people/plgmuravytskyi/slurm_jobdir/2053545/tmp/ipykernel_1549980/1699544185.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tokens, is_training)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# Run the transformer over the inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     embeddings = self.transformer(\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0minput_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/haiku/_src/module.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0;31m# Module names are set in the constructor. If `f` is the constructor then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/software/testing/software/Python/3.9.6-GCCcore-11.2.0/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/haiku/_src/module.py\u001b[0m in \u001b[0;36mrun_interceptors\u001b[0;34m(bound_method, method_name, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \u001b[0;34m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minterceptor_stack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbound_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m   ctx = MethodContext(module=self,\n",
      "\u001b[0;32m/net/ascratch/people/plgmuravytskyi/slurm_jobdir/2053545/tmp/ipykernel_1549980/1699544185.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, embeddings, mask, is_training)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Compute causal mask for autoregressive sequence modelling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# [B, H=1, T'=1, T]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mcausal_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtril\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B=1, H=1, T, T]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcausal_mask\u001b[0m  \u001b[0;31m# [B, H=1, T, T]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mtril\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/net/software/testing/software/SciPy-bundle/2021.10-intel-2021b/lib/python3.9/site-packages/numpy/lib/twodim_base.py\u001b[0m in \u001b[0;36mtril\u001b[0;34m(m, k)\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prev_time = time.time()\n",
    "state = initial_state\n",
    "for step in range(NUM_TRAINING_STEPS):\n",
    "    batch = preproc_data(next(train_di))\n",
    "    state, metrics = update(state, batch)\n",
    "    # We use JAX runahead to mask data preprocessing and JAX dispatch overheads.\n",
    "    # Using values from state/metrics too often will block the runahead and can\n",
    "    # cause these overheads to become more prominent.\n",
    "    if step % EVAL_INTERVAL == 0:\n",
    "      steps_per_sec = EVAL_INTERVAL / (time.time() - prev_time)\n",
    "      prev_time = time.time()\n",
    "      rng, new_rng = jax.random.split(rng)\n",
    "      valid_loss = loss_fn.apply(state.params, new_rng, preproc_data(next(test_di))) \n",
    "      metrics.update({'steps_per_sec': steps_per_sec, 'valid_loss': valid_loss})\n",
    "      print({k: float(v) for k, v in metrics.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hk.transform\n",
    "def generate(context: jnp.array, rng) -> jnp.array:\n",
    "    inp = context[:, 3:]\n",
    "    logits = forward(inp)  # (B, T*D, 256)\n",
    "    print(logits.shape)\n",
    "    \n",
    "    logits = jnp.concatenate((logits, jnp.zeros((BATCH_SIZE, 3, 256))), axis=1)\n",
    "    logits = jax.random.categorical(rng, logits, axis=-1)\n",
    "    res_bytes = logits.reshape((BATCH_SIZE, BLOCK_SIZE, EMBEDDING_SIZE))\n",
    "    \n",
    "    mask = jnp.array([1, 256, 256*256, 256*256*256])\n",
    "    res = jnp.apply_along_axis(lambda x: jnp.sum(x*mask), -1, res_bytes)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5757, 256)\n"
     ]
    }
   ],
   "source": [
    "test_batch = preproc_data(next(test_di))\n",
    "rng = jax.random.PRNGKey(SEED+10)\n",
    "rng, new_rng = jax.random.split(rng)\n",
    "b = generate.apply(state.params, new_rng, test_batch.inputs, new_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1440), (2, 5760))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape, test_batch.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dest = test_batch.targets.reshape((BATCH_SIZE, BLOCK_SIZE, EMBEDDING_SIZE))\n",
    "mask = jnp.array([1, 256, 256*256, 256*256*256])\n",
    "_dest = jnp.apply_along_axis(lambda x: jnp.sum(x*mask), -1, _dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE ... 60627.671875\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAE ... {jnp.mean(jnp.abs(_dest[:, :-1] - b[:, :-1]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(b[0, :300])\n",
    "plt.plot(_dest[0, :300])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
